---
tags: aud
---
# 7. Advanced Designs
## Auswahl algorithmischer Entwurfmethoden
### Divide & Conquer
L√∂se rekursiv (disjunkte) Teilprobleme
Siehe [[2. Sorting#Quicksort|Quicksort]], [[2. Sorting#Merge Sort|Merge Sort]] 
### Backtracking
Durchsuche iterativ L√∂sungsraum
Siehe [[#Backtracking]]
### Dynamisches Programmieren
L√∂se rekursiv (√ºberlappende) Teilprobleme durch Wiederverwenden/Speichern
Siehe [[#Dynamische Programmierung]]
### Greedy
Baue L√∂sung aus Folge lokal bester Auswahlen zusammen
Siehe [[#Greedy-Algorithmen]], [[6. Graph Algorithms#Algorithmus von Kruskal|Kruskal]], [[6. Graph Algorithms#Algorithmus von Prim|Prim]], [[6. Graph Algorithms#Dijkstra-Algorithmus|Dijkstra]]
### Metaheuristiken
√úbergeordnete Methoden f√ºr Optimierungsprobleme
Siehe [[#Metaheuristiken]]
# Backtracking
## Prinzip
Finde L√∂sungen $x := (x_1, x_2, \dots, x_n)$ per "Trial-and-Error", indem Teill√∂sung $(x_1, x_2, \dots, x_{i-1})$ durch Kandidaten $x_i$ erg√§nzt wird, bis Gesamtl√∂sung erreicht ist, oder bis festgestellt, dass keine Gesamtl√∂sung erreichbar, ist, dann wird Kandidat $x_{i-1}$ revidiert
## Beispiel: Sudoku
```
SUDOKU-BACKTRACKING(B) // B[0‚Ä¶3][0‚Ä¶3] board
	IF isFull(B) THEN
		print "solution: "+B;
	ELSE
		(i,j)=nextFreePos(B);
		FOR v=1 TO 4 DO
			IF isAdmissible(B,i,j,v) THEN // no rules broken?
				B[i,j]=v;
				SUDOKU-BACKTRACKING(B);
		B[i,j]=empty;
```
- Letzte Zeile wird nur ausgef√ºhrt, wenn die Teill√∂sung nicht zum Ziel gef√ºhrt hat, dann wird im vorherigen Feld die n√§chste Zahl versucht
Backtracking kann man als Tiefensuche auf Rekursionsbaum betrachten, wobei aussichtslose L√∂sungen evtl. fr√ºhzeitig abgeschnitten werden.
Es ist auch "intelligentere" ersch√∂pfende Suche, die aussichtslose L√∂sungen vorher aussortiert
## L√∂sungssuche
1. Finde eine L√∂sung
2. Finde alle L√∂sungen
3. Finde beste L√∂sung
## Beispiel: Regul√§rer Ausdruck
- Mustersuche in Strings
- Aufwand kann exponentiell werden
# Dynamische Programmierung
## Prinzip
- Teile Problem in (√ºberlappende) Teilprobleme
- L√∂se rekursiv Teilprobleme, verwende dabei Zwischenergebnisse wieder (Memoization)
- Rekonstruiere Gesamtl√∂sung
- Schwierigkeit: Finden geeigneter Rekursionen
## Beispiel: Fibonacci
```
Fib-Rek(n) // n>=1
	IF n=<2 THEN
		return 1;
	ELSE
		return Fib-Rek(n-1)+Fib-Rek(n-2);
```
- Vereinfachte Laufzeitabsch√§tzung: $T(n) \in \Theta(2^n)$
- Werte werden mehrfach berechnet
- L√∂sung: Werte zwischenspeichern (Memoization)
### Fibonacci mit Memoization
```
FibDyn(n) // n>=1
	F[]=ALLOC(n); //F_i at F[i-1]
	FOR i=0 TO n-1 DO F[i]=0;
	return FibDynRek(n-1,F);

FibDynRek(i,F) // i>=0
	IF F[i]!=0 THEN return F[i]; // already calculated
	IF i=<1 THEN
		f=1
	ELSE
		f=FibDynRek(i-1,F)+FibDynRek(i-2,F);
	F[i]=f;
	return f;
```
- Wenn Basisfall erreicht ist, nur noch Addieren und Auslesen zu tun
- Laufzeit $\Theta(n)$
## Minimum Edit Distance/Levenshtein-Distanz
Ziel:
- Messen der √Ñhnlichkeit von Texten
- Definiere 3 Buchstaben-Operationen:
  1. `ins(S,i,b)`: f√ºgt an `i`-ter Position Buchstabe `b` in String `S` ein
  2. `del(S,i)`: l√∂scht an `i`-ter Position Buchstaben in `S`
  3. `sub(S,i,b)`: ersetzt an `i`-ter Position in S den Buchstaben durch `b`
- Messe √Ñhnlichkeit anhand der Anzahl der ben√∂tigten Operationen zur √úberf√ºhrung zweier Texte ineinander
- Kosten/Operation ist 1, manchmal 2 f√ºr Substitution
- Nutze noch `copy(S,i)` f√ºr das Kopieren des `i`-ten Buchstabens, Kosten: 0
Algorithmische Sichtweise:
- String `X[1..m]` ist von links nach rechts in String `Y[1..n]` zu √ºberf√ºhren
- Zu jedem Zeitpunkt ist `X[1..i]` bereits in `Y[1..j]` transformiert
`D[i][j]` sei Distanz, um `X[1..i]` in `Y[1..j]` zu √ºberf√ºhren (`i,j >= 1`)
Betrachte nun n√§chsten Schritt um `X` in `Y` zu √ºberf√ºhren:
- `copy`: `D[i][j] = D[i-1][j-1]`
  Bereits `X[1..i-1]` in `Y[1..j-1]` √ºberf√ºhrt, jetzt kostenfrei kopieren
- `sub`: `D[i][j] = D[i-1][j-1] + 1`
  Bereits `X[1..i-1]` in `Y[1..j-1]` √ºberf√ºhrt, jetzt ersetzen
- `del`: `D[i][j] = D[i-1][j] + 1`
  Bereits `X[1..i-1]` in `Y[1..j]` √ºberf√ºhrt, jetzt `X[i]` l√∂schen
- `ins`: `D[i][j] = D[i][j-1] + 1`
  Bereits `X[1..i]` in `Y[1..j-1]` √ºberf√ºhrt, jetzt `Y[j]` einf√ºgen
Fasse `copy` und `sub` zusammen:
- `copy/sub`: `D[i][j] = D[i-1][j-1] + (X[i] != Y[j])` (Ausdruck ist 1 wenn wahr, sonst 0)
Suche nach der besten Strategie ist nun:
`D[i][j] = min {D[i-1][j-1] + (X[i] != Y[j]), D[i-1][j] + 1, D[i][j-1] + 1}`
Es gilt noch folgendes f√ºr die R√§nder:
- `D[0][j] = j`: F√ºge `j` Buchstaben `Y[1..j]` zu leerem String `X[1..0]` hinzu
- `D[i][0] = i`: L√∂sche `i` Buchstaben `X[1..i]`, um leeren String `Y[1..0]` zu erhalten
### Algorithmus
verwendet dynamische Programmierung und Memoization
```
MinEditDist(X,Y,m,n) // X=X[1..m], Y=Y[1..n]
	D[][]=ALLOC(m,n);
	FOR i=0 TO m DO D[i][0]=i;
	FOR j=0 TO n DO D[0][j]=j;
	FOR i=1 TO m DO
		FOR j=1 TO n DO
			IF X[i]=Y[j] THEN s=0 ELSE s=1;
			D[i][j]=min{D[i-1][j-1]+s,D[i-1][j]+1,D[i][j-1]+1};
	return D[m][n];
```
Laufzeit und Speicherbedarf $\Theta(mn)$
Dieser Algorithmus f√ºllt das zweidimensionale Array `D[][]` mit den Distanzen. Es gilt:
![[7 Minimum Edit Distance 1.png]]
Bei den Diagonalen Schritten gilt:
- Es wird kopiert, wenn die Distanz sich nicht ver√§ndert
- Es wird substituiert, wenn sich die Distanz erh√∂ht
Im Allgemeinen gibt es mehrere m√∂gliche Sequenzen
# Greedy-Algorithmen
## Prinzip
Finde L√∂sung $x = (x_1, x_2, \dots, x_n)$, indem Teill√∂sung $(x_1, x_2, x_{i-1})$ durch den Kandidaten $x_i$ erg√§nzt wird, der lokal am g√ºnstigsten erscheint
## Beispiele
- [[6. Graph Algorithms#Dijkstra-Algorithmus|Dijkstra]]: W√§hle immer Knoten, der die k√ºrzeste Distanz hat
- [[6. Graph Algorithms#Algorithmus von Kruskal|Kruskal]]: W√§hle jeweils leichteste Kante
Greedy-Algorithmen funktionieren oft, aber nicht immer (z.B. Dijkstra und negative Kantengewichte)
## Traveling Salesperson Problem (TSP)
Gegeben vollst√§ndiger (un-)gerichteter Graph $G = (V,E)$ mit Kantengewichten $w:E \to \mathbb{R}$, finde Tour ùëù mit minimalem Kantengewicht $w(p)$. Eine Tour ist ein Weg $p = (v_0, v_1, \dots, v_n)$ entlang der Kanten $(v_1, v_{i+1}) \in E, i = 0, 1, \dots, n-1$, der bis auf Start- und Endknoten $v_0 = v_n$ jeden Knoten genau einmal besucht ($V = \{v_0, v_!, \dots, v_{n-1}\}$)
Graph $G = (V,E)$ ist vollst√§ndig, wenn es f.a. $u,v \in V, u \ne v$ eine Kante $(u,v) \in E$ gibt.
Unvollst√§ndiger Graph mit Tour l√§sst sich erweitern, indem man fehlende Kanten $(u,v)$ verboten teuer macht: $w((u,v)) := |V| \cdot \max\limits_{e \in E}\{|w(e)|\} + 1$ f.a. $(u,v) \notin E$
### TSP vs. Dijkstra
- Allgemeiner TSP-Algorithmus:
  - Finde optimale Route, die durch jeden Knoten geht und zum Ausgangspunkt zur√ºckkehrt
- [[6. Graph Algorithms#Dijkstra-Algorithmus|Dijkstra]] l√∂st anderes Problem:
  - Finde optimalen Pfad vom Ausgangspunkt aus
  - Besucht eventuell nicht alle Knoten und betrachtet auch nicht R√ºckkehr
### Ansatz Greedy-Algorithmus f√ºr TSP
Starte mit beliebigem oder gegebenem Knoten.
Nehme vom gegenw√§rtigen Knoten aus die Kante zu noch nicht besuchtem Knoten, die kleinstes Gewicht hat.
Wenn kein Knoten mehr √ºbrig, gehe zu Startpunkt zur√ºck.
```
Greedy-TSP(G,s,w) // |V|=n, s starting node
	FOREACH v in V DO v.color=white;
	tour[]=ALLOC(n); tour[0]=s; tour[0].color=gray;
	FOR i=1 TO n-1 DO
		tour[i]=EXTRACT-MIN(adj(tour[i-1]));
			// get (white) neighbor with minimum edge weight
		tour[i].color=gray;
	return tour;
```
Ist zu gierig!
### Effizienter Algorithmus f√ºr TSP
Vermutlich schwierig zu finden
Siehe auch [[8. NP#NP-Vollst√§ndigkeit|NP-Vollst√§ndigkeit]]
# Metaheuristiken
## Heuristik
- Dedizierter Suchalgorithmus f√ºr Optimierungsproblem, der gute (eventuell nicht optimale) L√∂sung f√ºr spezielles Problem findet
- Problem-abh√§ngig: Arbeitet mit konkretem Problem
## Metaheuristik
- Allgemeine Vorgehensweise, um Suche f√ºr beliebige Optimierungsprobleme zu leiten
- Problem-unabh√§ngig: Arbeitet mit abstrakten Problemen
## Lokale Suche/Hill-Climbing-Strategie
1. Finde erste L√∂sung
2. Suche in N√§he bessere L√∂sungen, bis keine Verbesserung mehr/Zeit um
### Hill-Climbing-Algorithmus
```
HillClimbing(P) // maxTime constant
	sol=initialSol(P); // initial solution
	time=0;
	WHILE time<maxTime DO
		new=perturb(P,sol); // slightly alter solution
		IF quality(P,new)>quality(P,sol) THEN
			sol=new; // replace solution with new one iff it's better
		time=time+1;
	return sol;
```
### Beispiel TSP
- `initSol`: W√§hle beliebige Tour, z.B. per [[#Greedy-Algorithmen|Greedy-Algorithmus]]
- `perturb`: Tausche 2 zuf√§llige Knoten
- `quality`: Gewicht der aktuellen Tour
### Lokale/Globale Maxima
Eventuell bleibt Hill-Climbing-Algorithmus in lokalem Maximum h√§ngen, da stets nur leichte L√∂sungs√§nderungen in aufsteigender Richtung!
Siehe auch: [[6.3. Extremwerte]]
### Iterative, lokale Suche
1. F√ºhre [[#Lokale Suche/Hill-Climbing-Strategie|lokale Suche]] durch
2. Beginne Suche nochmal von vorne, z.B. mit neuer zuf√§lliger L√∂sung, eventuell auch mehrmals
3. Akzeptiere beste gefundene L√∂sung
Problem: Zuf√§llige L√∂sungen k√∂nnten auch schlecht sein
## Simulated Annealing
- "Annealing" in Metallverarbeitung:
  H√§rten von Metallen durch Erhitzen auf hohe Temperatur und langsames Abk√ºhlen
- Entscheide je nach Temperatur, in welche Richtung gesucht wird
1. Temperatur zu Beginn hoch, k√ºhlt langsam ab
2. Je h√∂her Temperatur, desto wahrscheinlicher Sprung in schlechte Richtung
- Mit Wahrscheinlichkeit in schlechte Richtung
### Ansatz
Akzeptiere auch L√∂sung `new` mit `quality(new)<quality(sol)`mit Wahrscheinlichkeit:
$rand(0,1) < e^{\frac{quality(new)-(quality(sol)}{temperature}}$
$temperature$ nimmt mit Zeit ab:
- Zu Beginn hei√üe Temperatur: Akzeptiere oft viel schlechtere L√∂sungen
- Am Ende k√ºhlere Temperatur: Akzeptiere selbst wenig schlechtere L√∂sungen fast nie
Gegen Ende fast [[#Lokale Suche/Hill-Climbing-Strategie|Hill-Climbing-Strategie]]

```
SimulatedAnnealing(P) // maxTime constant, TempSched[] temparature annealing
	sol=initialSol(P);
	time=0;
	WHILE time<maxTime DO
		new=perturb(P,sol);
		temperature=TempSched[time];
		d=quality(P,new)-quality(P,sol); r=random(0,1); // equally distributed
		IF d>0 OR r=<exp(d/temperature) THEN
			sol=new;
		time=time+1;
	return sol;
```
- Bestimmung eines guten "Annealing schedule" (Starttemperatur und Abnahme) ist nicht Teil der Veranstaltung
## Weitere Metaheuristiken
Es gibt noch viele mehr, z.B. Schwarmoptimierung, Ameisenkolonialisierung, ...
### Tabu Search
- Suche bessere L√∂sung in der N√§he ausgehend von aktueller L√∂sung
- Speichere eine Zeit lang schon besuchte L√∂sungen, vermeide diese L√∂sungen
- Wenn keine bessere L√∂sung in der N√§he, akzeptiere auch schlechtere L√∂sung
### Evolution√§re Algorithmen
- Beginne mit L√∂sungspopulation
- W√§hle beste L√∂sungen zur Reproduktion aus
- Bilde durch √úberkreuzungen und Mutationen der besten L√∂sungen neue L√∂sungen
- Ersetze schlechteste L√∂sungen durch diese neue L√∂sungen
