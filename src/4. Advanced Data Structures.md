---
tags: aud
---
# 4. Advanced Data Structures
# Rot-Schwarz-B√§ume (RS-B√§ume)
## Anwendung: Linux Completely Fair Scheduling
Verwendet RS-B√§ume. um Worst-Case-Laufzeit $(\log n)$ zu erreichen
`key`: virtual run time eines Prozesses in Sekunden
1. N√§chsten Prozess holen
2. Addiere zugewiesene Zeit
3. F√ºge mit aktualisierter Zeit wieder ein
## Baumkunde
Ein RS-Baum ist ein bin√§rer Suchbaum, sodass gilt:
1. Jeder Knoten ist rot oder schwarz (`x.color=red/black`)
2. Die Wurzel ist schwarz, wenn der Baum nicht leer ist
3. Wenn ein Knoten rot ist, sind seine Kinder schwarz (Nicht-Rot-Rot-Regel)
4. F√ºr jeden Knoten hat jeder Pfad im Teilbaum zu einem Blatt/Halbblatt die gleiche Anzahl an schwarzen Knoten
### Halbbl√§tter
Halbbl√§tter sind Knoten mit nur einem Kind
Halbbl√§tter im RS-Baum sind schwarz, sonst wird direkt mindestens eine Regel verletzt
## Schwarzh√∂he eines Knoten
Die Schwarzh√∂he eines Knoten `x` ist die eindeutige Anzahl an schwarzen Knoten auf dem Weg zu einem Blatt/Halbblatt im Teilbaum des Knoten
F√ºr leeren Baum setzt man $SH(nil) = 0$
## H√∂he eines RS-Baums
Ein RS-Baum mit $n$ Knoten hat maximale H√∂he $h \le 2 \cdot \log_2(n+1)$
Intuition:
1. In jedem Unterteilbaum gleiche Anzahl schwarzer Knoten auf jedem Pfad
2. Maximal zus√§tzlich gleiche Anzahl roter Knoten auf diesem Pfad
3. Daher einigerma√üen ausbalanciert und H√∂he $O(\log n)$
## Implementierungen mittels Sentinel
- `T.root.parent = T.sent`
- `T.sent.key=nil; T.sent.color=black;`
- `T.sent.parent = T.sent, T.sent.left=T.sent; T.sent.right=T.sent;`
- Alles immer wohldefiniert dank Einf√ºhruing von `T.sent` (Sentinel des Baumes T)
## Rotation
![[4 Rotation 1.png]]
```
rotateLeft(T,x) // x.right!=nil
	y=x.right;
	x.right=y.left;
	IF y.left != nil THEN
		y.left.parent=x;
	y.parent=x.parent;
	IF x.parent==T.sent THEN
		T.root=y
	ELSE
		IF x==x.parent.left THEN
			x.parent.left=y
		ELSE
			x.parent.right=y;
	y.left=x;
	x.parent=y;
```
- Rot-Schwarz-Baum-Bedingungen sind nach Rotation eventuell verletzt
- Laufzeit = $\Theta(1)$
## Einf√ºgen
1. Finde Elternknoten `y` wie im BST
2. F√§rbe neuen Knoten `z` rot
3. Stelle RS-Baum-Bedingung wieder her
```
insert(T,z) // z.left==z.right==nil;
	x=T.root; px=T.sent;
	WHILE x != nil DO
		px=x;
		IF x.key > z.key THEN
			x=x.left
		ELSE
			x=x.right;
	z.parent=px;
	IF px==T.sent THEN
		T.root=z
	ELSE
		IF px.key > z.key THEN
			px.left=z
		ELSE
			px.right=z;
	z.color=red;
	fixColorsAfterInsertion(T,z);
```
- Funktioniert wie beim BST mit Sentinel
## Aufr√§umen
```
fixColorsAfterInsertion(T,z)
	WHILE z.parent.color==red DO
		IF z.parent==z.parent.parent.left THEN
			y=z.parent.parent.right;
			IF y!=nil AND y.color==red THEN
				z.parent.color=black;
				y.color=black;
				z.parent.parent.color=red;
				z=z.parent.parent;
			ELSE
				IF z==z.parent.right THEN
					z=z.parent;
					rotateLeft(T,z);
				z.parent.color=black;
				z.parent.parent.color=red;
				rotateRight(T,z.parent.parent);
		ELSE
		// do the same, but exchange left and right
	T.root.color=black;
```
Laufzeit = $O(h) = O(\log n)$
## L√∂schen
- Gr√∂√ütenteils analog zum BST
- Sei `z` der entfernte Knoten und `y` der Knoten, der `z` ersetzt.
  Dann erbt `y` die Farbe von `z`, wenn `y` schwarz war, m√ºssen Farben angepasst werden
### Fixup bei `y.color==black`
$\Delta SH :=SH(\text{linker Teilbaum}) - SH(\text{rechter Teilbaum})$ f.a. Knoten
Beim L√∂schen kann die Schwarzh√∂he nur sinken
![[4 Rot-Schwarz-B√§ume 1.png]]
Fall $\Delta SH=1$ in `a` ist analog
Wenn `x` rot ist, setze `x` schwarz und fertig, somit nur schwarzer Fall zu betrachten
![[4 Rot-Schwarz-B√§ume 2.png]]
Fallunterscheidung:
1. `a` schwarz, `b` rot
   ![[4 Rot-Schwarz-B√§ume 3.png]]
   Wird zu allen F√§llen au√üer 2b)
2. a) `a` rot, `b` schwarz, `c,d` nicht rot
   ![[4 Rot-Schwarz-B√§ume 4.png]]
   `b` auf schwarz setzen, um urspr√ºngliche SH zu erreichen
2. b) `a` schwarz, `b` schwarz, `c,d` nicht rot
   ![[4 Rot-Schwarz-B√§ume 4.png]]
   Wenn `a` schwarz ist, dann gilt f√ºr Elternknoten $\Delta SH = \pm1$.
   Verfahre also rekursiv mit `a` als neuem `x` ^078a6c
3. `a` beliebig, `b` schwarz, `c` rot, `d` nicht rot
   ![[4 Rot-Schwarz-B√§ume 5.png]]
   Wird zu Fall 4
4. `a` beliebig, `b` schwarz, `c` beliebig, `d`  rot
   ![[4 Rot-Schwarz-B√§ume 6.png]]
   Urspr√ºngliche SH von vor der Entfernung wieder hergestellt
### Algorithmus
```
transplant(T,u,v) // with sentinel, also works for v==nil
	IF u.parent==T.sent THEN
		T.root=v
	ELSE
		IF u==u.parent.left THEN
			u.parent.left=v
		ELSE
			u.parent.right=v;
	IF v != nil THEN
		v.parent=u.parent;

delete(T,z)
	a=z.parent; dsh=nil;
	IF z.left==z.right==nil THEN // z leaf
		IF z.color==black AND z!=T.root THEN
			IF z.parent.left==z THEN dsh=right ELSE dsh=left;
		transplant(T,z,nil);
	ELSE IF z.left==nil THEN // z half leaf
		y=z.right;
		transplant(T,z,z.right);
		y.color=z.color;
	ELSE IF z.right==nil THEN // z half leaf
		y=z.left;
		transplant(T,z,z.left);
		y.color=z.color;
	ELSE // z has two children
		y=z.right; a=y; wentleft=false;
		WHILE y.left != nil DO
			a=y; y=y.left; wentleft=true;
		IF y.parent != z THEN
			transplant(T,y,y.right);
			y.right=z.right;
			y.right.parent=y;
		transplant(T,z,y);
		y.left=z.left;
		y.left.parent=y;
		IF y.color==black THEN
			IF wentleft THEN dsh=right ELSE dsh=left;
		y.color=z.color;
	IF dsh!=nil THEN fixColorsAfterDeletion(T,a,dsh);
```
- `a` ist ein Zeiger auf den Knoten, in dem die tiefste Imbalance entstehen k√∂nnte
- `dsh` = $\Delta SH$ f√ºr Knoten `a`: `nil` = 0, `left` = 1, `right` = -1
- In den F√§llen, in denen `z` ein Halbblatt ist, muss `y.color==red` sein, da sonst die SH-Regel verletzt w√§re.
  Dann kann man einfach `y` umh√§ngen und die Farbe von `z` kopieren
- In den F√§llen, in denen `z` kein (Halb-)Blatt ist, muss eine Fallunterscheidung stattfinden, je nachdem, ob `y` rechtes oder linkes Kind ist, davon ist dann auch die eventuelle Imbalance abh√§ngig
```
fixColorsAfterDeletion(T,a,dsh)
	IF dsh==right THEN // extra black node on the right
		x=a.left; b=a.right; c=b.left; d=b.right;
		IF x!=nil AND x.color==red THEN // x is red, easy to solve
			x.color=black;
		ELSE IF a.color==black AND b.color==red THEN // case 1
			rotateLeft(T,a);
			a.color=red; b.color=black;
			fixColorsAfterDeletion(T,a,dsh);
		ELSE IF a.color==red AND b.color==black // case 2a
				AND (c==nil OR c.color=black)
				AND (d==nil OR d.color=black) THEN
			a.color=black; b.color=red;
		ELSE IF a.color==black AND b.color==black // case 2b
				AND (c==nil OR c.color==black)
				AND (d==nil OR d.color==black) THEN
			b.color=red;
			IF a==a.parent.left THEN dsh=left
			ELSE IF a==a.parent.right THEN dsh=right ELSE dsh=nil;
			fixColorsAfterDeletion(T,a.parent,dsh);
		ELSE IF b.color==black AND c!=nil AND c.color==red // case 3
				AND (d==nil OR d.color==black) THEN
			rotateRight(T,b);
			c.color=black; b.color=black;
			fixColorsAfterDeletion(T,a,dsh);
		ELSE IF b.color==black AND d!=nil AND d.color==red THEN // case 4
			rotateLeft(T,a);
			b.color=a.color; a.color=black; d.color=black;
	ELSE // dsh==left, extra black node on the left
		// do the same, but exchange left and right
```
- `dsh=right` impliziert `b!=nil`
- Der letzte `ELSE`-branch ist f√ºr den linkslastigen Fall
- Au√üer in Fall [[#^078a6c|2b)]] f√ºhren rekursive Aufrufe im n√§chsten Schritt zum Rekursionsende
### Laufzeiten
`y` suchen hat wie beim BST Laufzeit $O(h) = O(\log n)$
Falls Rekursion in Fixup eintritt, ist die Laufzeit konstant
$\leadsto$ Gesamtlaufzeit L√∂schen = $O(h) = O(\log n)$
## Worst-Case-Laufzeiten RSB
- Einf√ºgen: $\Theta(\log n)$
- L√∂schen: $\Theta(\log n)$
- Suchen: $\Theta(\log n)$
# AVL-B√§ume
Optimierte Konstanten:
- RS-B√§ume: $h \le 2 \cdot \log n$
- AVL-B√§ume: $h \le 1.441 \cdot \log n$
Balance in Knoten $x$ mit angeh√§ngtem rechtem und linkem Teilbaum: $B(x) = height(\text{rechter Teilbaum}) - height(\text{linker Teilbaum})$
Konvention: $height(\text{leerer Baum}) = -1$
Ein AVL-Baum ist ein bin√§rer Suchbaum, sodass f√ºr die Balance $B(x)$ in jedem Knoten $x$ gilt: $B(x) \in \{-1, 0, +1\}$
## H√∂he
Ein AVL-Baum mit $n$ Knoten hat die maximale H√∂he $h \le 1.441 \cdot \log_2 n$
## AVL-Baum vs. RS-Baum
- AVL-Baum:
  Differenz von rechtem und linkem Teilbaum desselben Knotens $\le 1$
  Einf√ºgen und L√∂schen verletzen in der Regel √∂fter die Baum-Bedingung, mehr Aufwand zum Rebalancieren
- RS-Baum:
  H√∂henfaktor von rechtem und linkem Teilbaum desselben Knotens $\le 2$
  Suchen dauert eventuell l√§nger
AVL-B√§ume geeigneter, wenn mehr Such-Operationen und weniger Einf√ºge- und L√∂sch-Operationen
## AVL $\subset$ RS, AVL $\ne$ RS
Jeder nicht-leere AVL-Baum der H√∂he $h$ l√§sst sich als RS-Baum mit Schwarzh√∂he $\left\lceil \frac{h+1}{2} \right\rceil$ darstellen.
F√ºr gerade $h$ gibt es sogar einen Baum mit roter Wurzel, Schwarzh√∂he $\frac{h}{2}$, der alle anderen RS-Baumbedingungen erf√ºllt.
F√ºr jede H√∂he $h \ge 3$ gibt es einen RS-Baum, der kein AVL-Baum ist.
## Einf√ºgen
Funktioniert wie beim BST mit Sentinel, zuz√ºglich eventuellem Rebalancieren
```
insert(T,z) // z.left==z.right==nil;
	x=T.root; px=T.sent;
	WHILE x != nil DO
		px=x;
		IF x.key > z.key THEN
			x=x.left
		ELSE
			x=x.right;
	z.parent=px;
	IF px==T.sent THEN
		T.root=z
	ELSE
		IF px.key > z.key THEN
			px.left=z
		ELSE
			px.right=z;
	fixBalanceAfterInsertion(T,z);
```
### Rebalacieren
- Da immer in Bl√§ttern eingef√ºgt wird, werden nur die Knoten direkt dar√ºber eventuell nicht mehr balanciert
- Das Einf√ºgen muss nicht immer dazu f√ºhren, dass die Balance nicht mehr vorhanden ist
- Unterscheide 4 F√§lle:
1. Einfache Rotation:
   ![[4 AVL-B√§ume 1.png]]
   Nach dem Einf√ºgen und Rotieren ist die H√∂he gleich der H√∂he vor dem Einf√ºgen
2. Hier finden zwei Rotationen statt:
   ![[4 AVL-B√§ume 2.png]]
   ![[4 AVL-B√§ume 3.png]]
   H√∂he ist auch hier unver√§ndert
3. Fall 3 und 4 sind spiegelverkehrt und analog zu den F√§llen 1 und 2
   ![[4 AVL-B√§ume 4.png]]
### Laufzeit
Gesamtlaufzeit $O(h) = O(\log n)$
Suche hat Laufzeit $O(h)$, Rebalancieren ist nur einmal n√∂tig, also ist das konstant
## L√∂schen
Analog zum BST, aber Rebalacierung eventuell bis in die Wurzel n√∂tig
Gesamtlaufzeit $O(h) = O(\log n)$
## Worst-Case-Laufzeiten
- Einf√ºgen: $\Theta(\log n)$
- L√∂schen: $\Theta(\log n)$
- Suchen: $\Theta(\log n)$
AVL-B√§ume haben bessere theoretische Konstanten als Rot-Schwarz-B√§ume, sind je nach Daten und Operationen aber in der Praxis nur unwesentlich schneller.
# Splay-B√§ume
Selbst-organisierende Datenstrukturen
## Selbst-Organisierende Listen
Ansatz: einmal angefragte Werte werden voraussichtlich noch √∂fter angefragt
Variante f√ºr B√§ume: Splay trees
## Anwendung: SQUID
- Web-Cache-Proxy
- Speichert Access Control Listen (ACL) f√ºr http-Zugriffe als Splay-Tree
## Splay-Operationen
- Splay-B√§ume bilden Untermenge der BST
- Sp√ºle gesuchten oder neu eingef√ºgten Knoten an die Wurzel
- `splay(T,z)` = Folge von Zig-, Zig-Zig und Zig-Zag-Operationen
### Zig-Zag-Operation
Rechts-Links- oder Links-Rechts-Rotation
![[4 Splay-B√§ume 1.png]]
### Zig-Zig-Operation
Links-Links- oder Rechts-Rechts-Rotation
![[4 Splay-B√§ume 2.png]]
### Zig-Operation
Einfache Links- oder Rechts-Rotation
Wird verwendet, falls `z` direkt unter Wurzel h√§ngt
![[4 Splay-B√§ume 3.png]]
## Splay-Operation
```
splay(T,z)
	WHILE z != T.root DO
		IF z.parent.parent==nil THEN
			zig(T,z);
		ELSE
			IF z==z.parent.parent.left.left OR z==z.parent.parent.right.right THEN
				zigZig(T,z);
			ELSE
				zigZag(T,z);

zigZig(T,z)
	IF z==z.parent.left THEN
		rotateRight(T,z.parent.parent);
		rotateRight(T,z.parent);
	ELSE
		rotateLeft(T,z.parent.parent);
		rotateLeft(T,z.parent);

zigZag(T,z) // disclaimer: Not official, I wrote this!
	IF z==z.parent.left THEN
		rotateRight(T,z.parent);
		rotateLeft(T,z.parent);
	ELSE
		rotateLeft(T,z.parent);
		rotateRight(T,z.parent);

zig(T,z) // disclaimer: Not official, I wrote this!
	IF z==z.parent.left THEN
		rotateRight(T,z.parent);
	ELSE
		rotateLeft(T,z.parent);
```
Gesamtlaufzeit $O(h)$
## Suchen
```
search(T,k)
	x=T.root;
	WHILE x != nil AND x.key != k DO
		IF x.key < k THEN
			x=x.right
		ELSE
			x=x.left;
// now search is done
	IF x==nil THEN
		return nil
	ELSE
		splay(T,x);
		return T.root;
```
Suche und Splayen haben Laufzeit $O(h)$ $\leadsto$ Gesamtlaufzeit $O(h)$
Alternative: Bei erfolgloser Suche letzten besuchten Knoten nach oben splayen
## Einf√ºgen
1. Suche analog zum Einf√ºgen bei BST Einf√ºgepunkt
2. Sp√ºle eingef√ºgten Knoten `x` per Splay-Operation nach oben
### Laufzeit
1. Position im BST suchen: $O(h)$
2. `splay(T,x)`: $O(h)$
$\leadsto$ Gesamtlaufzeit $O(h)$
## L√∂schen
1. Sp√ºle gesuchten Knoten `x` per Splay-Operation nach oben
2. L√∂sche `x`
   Wenn einer der beiden Teilb√§ume leer ist, fertig
3. Sp√ºle den "gr√∂√üten" Knoten `y` im linken Teilbaum per Splay-Operation nach oben
   `y` kann keinen rechtes Kind haben, da gr√∂√üter Wert im linken Teilbaum
4. H√§nge rechten Teilbaum an `y` an
### Laufzeit
1. `splay(T,x)`: $O(h)$
2. `x` l√∂schen: $O(1)$
3. `y` im linken Teilbaum `L` finden, `splay(L,y)`: $O(h)+ O(h) = O(h)$
4. Anh√§ngen: $O(1)$
$\leadsto$ Gesamtlaufzeit $O(h)$
## Laufzeit Splay-B√§ume
- Amortisierte Laufzeit:
  Laufzeit pro Operation √ºber mehrere Operationen hinweg
- F√ºr $m \ge n$ Operationen auf einem Splay-Baum mit maximal $n$ Knoten ist die Worst-Case-Laufzeit $O(m \cdot \log_2 n)$, also $O(\log_2 n)$ pro Operation.
- Zus√§tzlich: Oft gesuchte Elemente werden sehr schnell gefunden
# (Bin√§re Max-)Heaps
Ein bin√§rer Max-Heap ist ein bin√§rer Baum, der
1. bis auf das unterste Level vollst√§ndig und im untersten Level von links gef√ºllt ist
2. F√ºr alle Knoten $x \ne T.root$ gilt: $x.parent.key \ge x.key$
- Heaps sind keine BSTs, linke Kinder k√∂nnen gr√∂√üere Werte als rechte Kinder haben!
- Bei Min-Heaps sind die Werte in Elternknoten jeweils kleiner
## Eigenschaften
- Da Baum (fast) vollst√§ndig ist, gilt $h \le \log n$
- Maximum des Heaps steht in der Wurzel
## Heaps durch Arrays
- speichere Anzahl Knoten in `H.length` (leerer Heap `H.length==0`)
- Duale Sichtweise als Pointer oder als Array ($j$ ist Index im Array):
  - $j.parent = \left\lceil \frac{j}{2} \right\rceil - 1$
  - $j.left = 2(j + 1) - 1$
  - $j.right = 2(j + 1)$
## Einf√ºgen
- Position durch Baumstruktur vorgegeben
- Vertausche nach oben, bis Max-Eigenschaft wieder erf√ºllt
```
insert(H,k) // as (unlimited) array
	H.length=H.length+1;
	H.A[H.length-1]=k;
	i=H.length-1;
	WHILE i>0 AND H.A[i] > H.A[i.parent]
		SWAP(H.A,i,i.parent);
		i=i.parent;
```
Laufzeit $O(h) = O(\log n)$
## L√∂sche Maximum
1. Ersetze Maximum durch "letztes" Blatt
2. Stelle Max-Eigenschaften wieder her, indem Knoten nach unten gegen das Maximum der beiden Kinder getauscht wird (`heapify`)
```
extract-max(H) // as (unlimited) array
	IF isEmpty(H) THEN
		return error ‚Äòunderflow‚Äò
	ELSE
		max=H.A[0];
		H.A[0]=H.A[H.length-1];
		H.length=H.length-1;
		heapify(H,0);
		return max;

heapify(H,i) // as (unlimited) array
	maxind=i;
	IF i.left<H.length AND H.A[i]<H.A[i.left] THEN
		maxind=i.left;
	IF i.right<H.length AND H.A[maxind]<H.A[i.right] THEN
		maxind=i.right;
	IF maxind != i THEN
		SWAP(H.A,i,maxind);
		heapify(H,maxind);
```
Laufzeit beider Algorithmen $O(h) = O(\log n)$
## Heap-Konstruktion aus Array
Bl√§tterindizes: $\left\lceil \frac{n-1}{2} \right\rceil, \dots, n-1$
Bl√§tter sind f√ºr sich triviale Max-Heaps
Baue rekursiv per `heapify` Max-Heaps f√ºr Teilb√§ume
```
buildHeap(H) // array A has already been copied to H.A
	H.length=A.length;
	FOR i = ceil((H.length-1)/2)-1 DOWNTO 0 DO
		heapify(H,i);
```
Laufzeit $O(n \cdot h) = O(n \log n)$
## Heap-Sort
Gibt Eintr√§ge in Array `A` in absteigender Gr√∂√üe aus
```
heapSort(H) // array A has already been copied to H.A
	buildHeap(H);
	WHILE !isEmpty(H) DO PRINT extract-max(H);
```
Laufzeit $O(n \cdot h) = O(n \log n)$
Alternativ: speichere in jeder `WHILE`-Iteration `max=extract-max(H)` in `H.A[H.length]=max`, um sortierte Liste am Ende aufsteigend im Array `A` zu haben.
## Abstrakter Datentyp Priority Queue
- `new(Q)`: erzeugt neue, leere Priority Queue namens `Q`
- `isEmpty(Q)`: gibt an, ob Queue `Q` leer
- `max(Q)`: gibt "gr√∂√ütes" Element aus Queue `Q` zur√ºck, Fehler wenn leer
- `extract-max(Q)`: gibt "gr√∂√ütes" Element aus `Q` zur√ºck, l√∂scht es aus `Q`, Fehler wenn leer
- `insert(Q,k)`: f√ºgt Wert `k` zu Queue `Q` hinzu
Implementation kann Priority Heap verwenden (Java)
# B-B√§ume
Ein B-Baum von Grad $t$ ist ein Baum, bei dem
1. jeder Knoten au√üer der Wurzel zwischen $t-1$ und $2t-1$ Werte `key[0], key[1], ...` hat, die Wurzel hat zwischen 1 und $2t-1$ Werte
2. die Werte innerhalb eines Knoten aufsteigend geordnet sind
3. die Bl√§tter alle die gleiche H√∂he haben
4. jeder innerer Knoten mit $n$ Werten $n+1$ Kinder hat, sodass f√ºr alle Werte $k_j$ aus dem $j$-ten Kind gilt: $k_0 \le key[0] \le k_1 \le key[1] \le \dots \le k_{n-1} \le key[n-1] \le k_n$
## Darstellung
- `x.n`: Anzahl Werte des Knotens `x`
- `x.key[0], ..., x.key[x.n-1]`: Geordnete Werte in Knoten `x`
- `x.child[0], ..., x.child[x.n]`: Zeiger auf Kinder in Knoten `x`
## H√∂he
- Mindestens 1 Wert in Wurzel
- Mindestens 2 Knoten in Tiefe 1 mit jeweils mindestens $t$ Kindern
- Mindestens $2t$ Knoten in n√§chster Tiefe mit jeweils mindestens $t$ Kindern
- Mindestens $2t^2$ Knoten in n√§chster Tiefe mit jeweils mindestens $t$ Kindern, usw.
- In jedem Knoten au√üer Wurzel mindestens $t-1$ Werte
- Anzahl Werte $n$ im B-Baum im Vergleich zur H√∂he $h$: $n \ge 2t^h-1$, also $log_t\frac{n+1}{2} \ge h$
- $\leadsto$ Ein B-Baum vom Grad $t$ mit $n$ Werten hat maximale H√∂he $h \le \log_t\frac{n+1}{2}$
- F√ºr gr√∂√üere $t$ also flacher als vollst√§ndiger Bin√§rbaum
## Anwendung
- MySQL speichert Werte in B-B√§umen
- Lesen/Schreiben in Bl√∂cken: mehrere Werte (z.B. Index-Eintr√§ge) auf einmal
## Suche
```
search(x,k)
	WHILE x != nil DO
		i=0;
		WHILE i < x.n AND x.key[i] < k DO i=i+1;
		IF i < x.n AND x.key[i]==k THEN
			return (x,i);
		ELSE
			x=x.child[i];
	return nil;
```
\2. While-Schleife: Maximal $2t \in O(1)$ Iterationen
Laufzeit $O(t \cdot h) = O(\log_t n)$
## Baumkunde
- B-Baum vom Grad $t$: max. $2t$, min. $t$ Kinder pro Knoten $\ne$ Wurzel
  Alternative Definition: max. $t$, min. $\frac{t}{2}$ Kinder pro Knoten $\ne$ Wurzel
- 2-3-4-Baum/(2,4)-Baum: B-Baum mit $t = 2$
- B+-Baum: alle Werte in Bl√§ttern, innerer Knoten enthalten Werte erneut
  Vorteil: innere Knoten speichern nur kurzen Schl√ºssel, nicht auch noch Daten(-zeiger)
  Nachteil: Findet Werte erst im Blatt
  Alternativer Name: B*-Baum
- Alternative Bedeutung B*-Baum: B-Baum mit F√ºllgrad min. $\frac{2}{3}$ pro Knoten $\ne$ Wurzel
## Einf√ºgen
### Idee
- Einf√ºgen erfolgt immer in einem Blatt
- Wenn Blatt weniger als $2t-1$ Werte hat, dann einf√ºgen und fertig
- Wenn nicht:
#### Splitten
- Wenn Blatt bereits $2t-1$ Werte, dann teile es in zwei Bl√§tter mit je $t-1$ Werten, f√ºge mittleren Wert im Elternknoten ein
- Wenn dadurch Elternknoten mehr als $2t-1$ Werte hat, rekursiv nach oben
- Splitten an der Wurzel: Neue Wurzel wird erzeugt, H√∂he des Baumes w√§chst um 1
B-Baum-Einf√ºgen splittet beim Suchen und l√§uft nur einmal hinab, sonst werden teure Disk-Operationen zweimal ausgef√ºhrt, einmal beim ab-, einmal beim aufsteigen.
### Informeller Algorithmus
```
insert(T,z)
	Wenn Wurzel schon 2t-1 Werte, dann splitte Wurzel
	Suche rekursiv Einf√ºgeposition:
		Wenn zu besuchendes Kind 2t-1 Werte, splitte es erst
	F√ºge z in Blatt ein
```
Laufzeit $O(t \cdot h) = O(\log_t n)$
Schleifeninvariante:
Bei der Suche hat der aktuelle Knoten immer weniger als $2t-1$ Werte, da sonst vorher gesplitted.
Eventuelles Splitten ist also problemlos m√∂glich.
Auch das Blatt hat am Ende weniger als $2t-1$ Werte.
## L√∂schen
### L√∂schen im Blatt
- Wenn Blatt noch mehr als $t-1$ Werte hat, dann einfach entfernen
- Wenn $t-1$ Werte im Blatt mit zu l√∂schendem Wert sind, linker oder rechter Geschwisterknoten hat mind. $t$ Werte, dann rotiere Werte von Geschwisterknoten und Elternknoten:
  ![[4 B-B√§ume 1.png]]
- Wenn $t-1$ Werte im Blatt mit zu l√∂schendem Wert sind, linker oder rechter Geschwisterknoten haben auch $t-1$ Werte, dann verschmelze einen Geschwisterknoten mit Wert aus Elternknoten, dieser hat nun eventuell zu wenig Werte:
  ![[4 B-B√§ume 2.png]]
### L√∂schen im inneren Knoten
- Verschieben:
  Wenn sich mehr als $t-1$ Werte in einem der beiden Kindknoten befinden, dann gr√∂√üten Wert (vom linken Kind) bzw. kleinsten Wert (vom rechten Kind) nach oben kopieren
- Verschmelzen:
  Wenn sich jeweils ùë° ‚àí 1 Werte in beiden Kindknoten befinden, dann Kindknoten verschmelzen, eventuell hat Elternknoten nun zu wenig Werte:
  ![[4 B-B√§ume 3.png]]
B-Baum-L√∂schen l√§uft auch nur einmal hinab, stelle dazu sicher, dass zu besuchendes Kind mindestens $t$ Werte hat.
### Allgemeines Verschmelzen ohne L√∂schen
Zu besuchendes Kind, rechter,  linker Geschwisterknoten (sofern existent) haben nur $t-1$ Werte.
Dann ist Verschmelzen ohne weitere √Ñnderungen m√∂glich, wenn der Elternknoten vorher mindestens $t$ Werte hat.
### Allgemeines Rotieren/Verschieben ohne L√∂schen
Zu besuchendes Kind hat nur $t-1$ Werte, aber ein Geschwisterknoten hat mehr als $t-1$ Werte, dann kann man dies ohne √Ñnderungen oberhalb tun
### Informeller Algorithmus
```
delete(T,k)
	Wenn Wurzel nur 1 Wert und beide Kinder t-1 Werte haben, verschmelze Wurzel und Kinder (reduziert H√∂he um 1)
	Suche rekursiv L√∂schposition:
		Wenn zu besuchendes Kind nur t-1 Werte hat, verschmelze es oder rotiere/verschiebe
	Entferne Wert k in inneren Knoten/Blatt
```
Laufzeit $O(t \cdot h) = O(\log_t n)$
Schleifeninvariante:
Aktueller Knoten hat zu diesem Zeitpunkt mindestens $t$ Werte, sonst w√§re er vorher verschmolzen worden oder es w√§re rotiert worden.
Beim Verschmelzen/Verschieben des Kindes kann die Anzahl der Werte im aktuellen Knoten nicht unter $t-1$ fallen.
Entfernen aus Blatt problemlos m√∂glich, da mindestens $t$ Werte vorhanden.
Entfernen im inneren Knoten durch Verschieben oder Verschmelzen.
## Worst-Case-Laufzeiten
- Einf√ºgen: $\Theta(\log_t n)$
- L√∂schen: $\Theta(\log_t n)$
- Suchen: $\Theta(\log_t n)$
- $O$-Notation versteckt konstanten Faktor $t$ f√ºr Suche innerhalb eine Knoten:
  $t \cdot \log_t n = t \cdot \frac{\log_2 n}{\log_2 t}$ ist in der Regel gr√∂√üer als $\log_2 n$, also nur vorteilhaft, wenn Daten blockweise eingelesen werden.
